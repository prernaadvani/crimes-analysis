[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NYC Crimes Analysis",
    "section": "",
    "text": "1 Introduction\nWhen choosing a topic for our final project, we brainstormed a few different ideas that were relevant to our current environment. There initial ideas included a climate analysis - we found data on regional climate variables (ex: precipitation, snow, max and min temperature, etc.), economic variables (ex: unemployment, inflation, etc.), prior Google Mobility data (indexed time spent in Parks, Grocery Stores, etc.), and NYPD crimes data (frequency of top 7 crimes, crimes at NY parks, etc.).\nTo narrow our search, we completed some high level analysis to examine the quality and depth of our data options. We looked at the different variables offered in each dataset, the duration and frequency of data collection, and how we may potentially be able to tie multiple datasets together.\nWe decided to analyze the crimes at NYC parks for a few different reasons. First, as NY residents, an analysis of a topic directly relevant to both of our lives was of high interest. Secondly, we saw that the depth of data available directly from the NYPD was robust, covering around 1 decade worth of data across different parks and different types of crimes. We immediately had several ideas for different types of analysis, data slicing, and visualizations we could show with this dataset. Lastly, in thinking about how it may correlate to other factors, we are planning to merge crime data with unemployment rates to determine if there are any correlations. Unemployment data is a typical socio-economic indicator. We may also tentatively merge this data with Google Mobility data for time spent at parks in NY to determine if there is a correlation there, though we note that the data is only available for a few years and have been discontinued. Through this comprehensive analysis, our goal is to paint a clearer picture of safety in New York City’s parks and how it intersects with larger social and economic trends."
  },
  {
    "objectID": "data.html#description",
    "href": "data.html#description",
    "title": "2  Data",
    "section": "2.1 Description",
    "text": "2.1 Description\nAs we are studying crimes at NYC parks and potential reasons, we collected three datasets: crimes, unemployment, and mobility data.\nFirst, we collected crime data in NYC from NYPD official websites focused on crime statistics. The link for the data is NYPD Crime Statistics. The data covers quarters from 2014 to 2023. The data for each quarter shows features like numbers of crimes, park sizes, and boroughs. The data format is an excel file for each quarter that we plan to download onto our local drives and import into R. We will then clean and merge data for all quarters. For our study, we first focused on three factors: total number of different types of crimes, park size categories, and boroughs. Further, we investigated the influence of specific types of crimes.\nSecond, we collected unemployment data from U.S. Bureau of Labor Statistics official website focused on NYC area. The link of data is NYC Unemployment Statistics. Additionally, BLS Data Finder offered on this website is able to search unemployment data for NYC. We are downloading an excel file with all of the data from 2013-2023 onto our local drive and importing it into R. Monthly unemployment data is available from 2013 to 2023. Columns include the year, month, and annual average unemployment in wide format.\nLast, we looked at high level mobility data from Google Community Mobility Reports. The link of data is Mobility Data. Daily data of movement trend in places such as parks is available in the Covid-19 period. A few restrictions on this data include: it is only available from February 2020 to October 2022, and the data must be scraped from the published reports. If we want to use the data, we will have to use a third party source that has scraped data into a csv file. The link for a potential scrape is from this GitHub Repo. Though the dataset includes other locations (such as grocery stores), and other regions (different states in the US), we will only be focusing on parks and NYC, if permitted to use this dataset. We will be importing this data directly from github as a csv file for our analysis. The values provided show deviations from the baseline, which is set as the 5-week period Jan 3–Feb 6, 2020. We also note that any correlations generated from this data are at risk of containing a confunding variable since the data is only available during the pandemic period."
  },
  {
    "objectID": "data.html#research-plan",
    "href": "data.html#research-plan",
    "title": "2  Data",
    "section": "2.2 Research Plan",
    "text": "2.2 Research Plan\nWe plan to use NYC crimes data to track how the frequency of different types of crimes has changed across time and different boroughs. We will then use unemployment data to glean and additional insights on correlations that may exist. Lastly, if permitted, we can derive any impacts of park visit frequency from February 2020-October 2022. A few different ideas for analysis are included below:\n\nTime series analysis for crimes data. We will conduct time series analysis to look into components including long term trends, seasonality (systematic, calendar related movements), and irregularity (unsystematic, short term fluctuations). In addition to overall crime trends, we will further analyze how specific types of crimes (murder, rape, etc.) vary over time.\nHeatmaps and bar charts for crimes data. We will illustrate crimes data in heatmaps based on boroughs and periods to find time and regional differences. We will use bar charts to show the total number of crimes in each borough, allowing for easy comparison across regions. We will also include bar charts that compare the annual crimes in each borough across different years.\nRelationship between crimes and employment rate. We will look into trends for total number of crimes and unemployment rates both annually and quarterly. We will first demonstrate these two variables in scatterplots. In detail, we will add trend lines and calculate correlation coefficients for these scatterplots to quantify the strength of the relationship.\nRelationship between crimes and mobility data. For February 2020 to October 2022, we may look into the number of crimes and park attendance levels, investigating whether visitor flow affects crimes."
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\n\n2.3.1 Crimes Data\nFirst, we examine the crimes datasets. We will begin by first pulling data for 3Q23 for a high level overview. After determining data cleans, we will merge data for multiple quarters. We can see that there are few missing values in our data. We can just delete the records with missing values.\n\n\nCode\nlibrary(readxl)\nnyc_park_crime_stats_q3_2023 &lt;- read_excel(\"~/Desktop/crime_data/nyc-park-crime-stats-q3-2023.xlsx\") #read data\n\n\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n\n\nCode\n# show part of data\nhead(nyc_park_crime_stats_q3_2023)\n\n\n# A tibble: 6 × 12\n  3rd QTR PARK CRIME REP…¹ ...2  ...3  ...4  ...5  ...6  ...7  ...8  ...9  ...10\n  &lt;chr&gt;                    &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 SEVEN MAJOR COMPLAINTS   &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n2 Report covering the per… &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt;  &lt;NA&gt; \n3 PARK                     BORO… SIZE… CATE… MURD… RAPE  ROBB… FELO… BURG… GRAN…\n4 CORONA HEALTH SANCTUARY  QUEE… 0.101 PLAY… 0     0     0     0     0     0    \n5 LT. FEDERICO NARVAEZ TO… BROO… 0.125 PLAY… 0     0     0     0     0     0    \n6 SOBEL PLAYGROUND         BROO… 0.135 PLAY… 0     0     0     0     0     0    \n# ℹ abbreviated name: ¹​`3rd QTR PARK CRIME REPORT`\n# ℹ 2 more variables: ...11 &lt;chr&gt;, ...12 &lt;chr&gt;\n\n\nWe can see that there are a few extra rows of data at the top and row 3 needs to be the header.\n\n\nCode\ncolnames(nyc_park_crime_stats_q3_2023) = nyc_park_crime_stats_q3_2023[3,] #set row 3 as header\nnyc_park_crime_stats_q3_2023 = nyc_park_crime_stats_q3_2023[-c(1,2,3), ] #remove first 3 rows of data\nhead(nyc_park_crime_stats_q3_2023) #new data column names\n\n\n# A tibble: 6 × 12\n  PARK     BOROUGH `SIZE (ACRES)` CATEGORY MURDER RAPE  ROBBERY `FELONY ASSAULT`\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;           \n1 CORONA … QUEENS  0.101          PLAYGRO… 0      0     0       0               \n2 LT. FED… BROOKL… 0.125          PLAYGRO… 0      0     0       0               \n3 SOBEL P… BROOKL… 0.135          PLAYGRO… 0      0     0       0               \n4 BILL BO… MANHAT… 0.172          BASKETB… 0      0     0       0               \n5 WILLIAM… QUEENS  0.230          PLAYGRO… 0      0     1       2               \n6 SUNSHIN… MANHAT… 0.240          PLAYGRO… 0      0     0       0               \n# ℹ 4 more variables: BURGLARY &lt;chr&gt;, `GRAND LARCENY` &lt;chr&gt;,\n#   `GRAND LARCENY OF MOTOR VEHICLE` &lt;chr&gt;, TOTAL &lt;chr&gt;\n\n\nHere, we show the features of crimes data: park, borough, park size, number of crimes by type of crime.\n\n\nCode\n# examine whether thre are missing values\ncolSums(is.na(nyc_park_crime_stats_q3_2023))\n\n\n                          PARK                        BOROUGH \n                             0                              1 \n                  SIZE (ACRES)                       CATEGORY \n                             1                              1 \n                        MURDER                           RAPE \n                             0                              0 \n                       ROBBERY                 FELONY ASSAULT \n                             0                              0 \n                      BURGLARY                  GRAND LARCENY \n                             0                              0 \nGRAND LARCENY OF MOTOR VEHICLE                          TOTAL \n                             0                              0 \n\n\nHere, we can see there are only some missing values in each column, which are negligible. Therefore we just delete the records with missing values.\n\n\nCode\nnyc_park_crime_stats_q3_2023_clean &lt;- na.omit(nyc_park_crime_stats_q3_2023)\nhead(nyc_park_crime_stats_q3_2023_clean)\n\n\n# A tibble: 6 × 12\n  PARK     BOROUGH `SIZE (ACRES)` CATEGORY MURDER RAPE  ROBBERY `FELONY ASSAULT`\n  &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;          &lt;chr&gt;    &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;           \n1 CORONA … QUEENS  0.101          PLAYGRO… 0      0     0       0               \n2 LT. FED… BROOKL… 0.125          PLAYGRO… 0      0     0       0               \n3 SOBEL P… BROOKL… 0.135          PLAYGRO… 0      0     0       0               \n4 BILL BO… MANHAT… 0.172          BASKETB… 0      0     0       0               \n5 WILLIAM… QUEENS  0.230          PLAYGRO… 0      0     1       2               \n6 SUNSHIN… MANHAT… 0.240          PLAYGRO… 0      0     0       0               \n# ℹ 4 more variables: BURGLARY &lt;chr&gt;, `GRAND LARCENY` &lt;chr&gt;,\n#   `GRAND LARCENY OF MOTOR VEHICLE` &lt;chr&gt;, TOTAL &lt;chr&gt;\n\n\nTo visualize the crimes by borough, we first compute the total crimes.\n\n\nCode\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nnyc_park_crime_stats_q3_2023_clean &lt;- nyc_park_crime_stats_q3_2023_clean %&gt;%\n  mutate_at(vars(TOTAL), as.numeric)\n\n# compute total crimes for boroughs\nborough_crime_totals &lt;- nyc_park_crime_stats_q3_2023_clean %&gt;%\n  group_by(BOROUGH) %&gt;%\n  summarize(Total_Crimes = sum(TOTAL, na.rm = TRUE))\n\nprint(borough_crime_totals)\n\n\n# A tibble: 6 × 2\n  BOROUGH         Total_Crimes\n  &lt;chr&gt;                  &lt;dbl&gt;\n1 BRONX                     51\n2 BROOKLYN                  98\n3 BROOKLYN/QUEENS            5\n4 MANHATTAN                143\n5 QUEENS                    94\n6 STATEN ISLAND              7\n\n\nThen we use bar chart to show the results.\n\n\nCode\nlibrary(ggplot2)\nborough_data = as.data.frame(borough_crime_totals)\n\nggplot(borough_data, aes(x = BOROUGH, y = Total_Crimes, fill = BOROUGH)) +\n    geom_bar(stat=\"identity\") +\n    theme_minimal() +\n    labs(title=\"NYC Park Crime Distribution by Borough in 3Q23\", x=\"Borough\", y=\"Total Crimes\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\n\n\n2.3.2 Unemployment Rate Data\nThen, we examine the dataset for unemployment rates.\n\n\nCode\nunemployment_rate &lt;- read_excel(\"~/Desktop/unemployment_rate.xlsx\") #read data\nprint(unemployment_rate)\n\n\n# A tibble: 11 × 14\n    Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2013   9.1   9.1   9     9     8.9   8.9   8.9   8.9   8.7   8.6   8.4   8.2\n 2  2014   8     7.8   7.6   7.5   7.3   7.1   6.9   6.8   6.6   6.5   6.4   6.3\n 3  2015   6.2   6.1   6     5.9   5.7   5.6   5.4   5.2   5.2   5.1   5.2   5.2\n 4  2016   5.2   5.2   5.2   5.1   5.1   5.2   5.2   5.3   5.2   5.2   5     4.9\n 5  2017   4.7   4.6   4.5   4.5   4.5   4.6   4.6   4.6   4.5   4.5   4.4   4.3\n 6  2018   4.3   4.2   4.2   4.1   4.1   4     4     4     4.1   4.2   4.3   4.3\n 7  2019   4.3   4.2   4.1   4     3.9   3.8   3.8   3.8   3.8   3.8   3.9   4  \n 8  2020   4.1   4.3   4.5  12.7  21.4  17.1  16.5  14.8  14.3  13.2  12.9  12.6\n 9  2021  12.3  11.9  11.4  11.1  10.4  10.5   9.8   9.6   8.8   8.5   8.1   8  \n10  2022   7.6   6.9   6.3   5.9   5.5   5.2   4.9   4.6   4.9   5.2   5.2   5.1\n11  2023   5.3   5.4   5.3   5.4   5.3   5.4   5.3   5.3   5.3   5.4  NA    NA  \n# ℹ 1 more variable: Avg &lt;lgl&gt;\n\n\nIt’s obvious that the missing values are average unemployment rates for each year and the last two months in 2023. For the average rates, we can directly compute the average rates based on monthly rates.\n\n\nCode\nunemployment_rate$Avg &lt;- rowMeans(unemployment_rate[, 2:13], na.rm = TRUE)\n\n\nAs for missing values for the last two months in 2023, it’s reasonable because there is no data available yet for months in the future. We can just ignore the missing values here.\n\n\nCode\nprint(unemployment_rate)\n\n\n# A tibble: 11 × 14\n    Year   Jan   Feb   Mar   Apr   May   Jun   Jul   Aug   Sep   Oct   Nov   Dec\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1  2013   9.1   9.1   9     9     8.9   8.9   8.9   8.9   8.7   8.6   8.4   8.2\n 2  2014   8     7.8   7.6   7.5   7.3   7.1   6.9   6.8   6.6   6.5   6.4   6.3\n 3  2015   6.2   6.1   6     5.9   5.7   5.6   5.4   5.2   5.2   5.1   5.2   5.2\n 4  2016   5.2   5.2   5.2   5.1   5.1   5.2   5.2   5.3   5.2   5.2   5     4.9\n 5  2017   4.7   4.6   4.5   4.5   4.5   4.6   4.6   4.6   4.5   4.5   4.4   4.3\n 6  2018   4.3   4.2   4.2   4.1   4.1   4     4     4     4.1   4.2   4.3   4.3\n 7  2019   4.3   4.2   4.1   4     3.9   3.8   3.8   3.8   3.8   3.8   3.9   4  \n 8  2020   4.1   4.3   4.5  12.7  21.4  17.1  16.5  14.8  14.3  13.2  12.9  12.6\n 9  2021  12.3  11.9  11.4  11.1  10.4  10.5   9.8   9.6   8.8   8.5   8.1   8  \n10  2022   7.6   6.9   6.3   5.9   5.5   5.2   4.9   4.6   4.9   5.2   5.2   5.1\n11  2023   5.3   5.4   5.3   5.4   5.3   5.4   5.3   5.3   5.3   5.4  NA    NA  \n# ℹ 1 more variable: Avg &lt;dbl&gt;\n\n\nThe following line graph is a time series visualization showing the variation in unemployment rates for each month across different years. There are no gaps in this plot, verifying no missing values in the dataset.\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyr)\n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nCode\nlibrary(dplyr)\n\nunemployment_long &lt;- unemployment_rate %&gt;%\n  pivot_longer(cols = Jan:Dec, names_to = \"Month\", values_to = \"UnemploymentRate\") %&gt;%\n  mutate(Month = match(Month, month.abb))\n\nggplot(unemployment_long, aes(x = Year + (Month-1)/12, y = UnemploymentRate)) +\n  geom_line() +\n  scale_x_continuous(breaks = unique(unemployment_long$Year)) +\n  labs(title = \"Monthly Unemployment Rate Over Years\",\n       x = \"Year\",\n       y = \"Unemployment Rate (%)\") +\n  theme_minimal()\n\n\nWarning: Removed 2 rows containing missing values (`geom_line()`).\n\n\n\n\n\n\n\n2.3.3 Mobility Data\nWe examine the mobility dataset. We only focus on the feature: parks_percent_change_from_baseline.\n\n\nCode\n#import data\n\ndata = read.csv('https://raw.githubusercontent.com/ActiveConclusion/COVID19_mobility/master/google_reports/mobility_report_US.csv')\n\n# Step 2: Filter for New York Data and Parks\nnyc_data &lt;- data %&gt;%\n  filter(state == \"New York\") %&gt;%\n  select(county, date, parks)\nhead(nyc_data)\n\n\n  county       date parks\n1  Total 2020-02-15    -2\n2  Total 2020-02-16    13\n3  Total 2020-02-17    23\n4  Total 2020-02-18    -4\n5  Total 2020-02-19    11\n6  Total 2020-02-20     0\n\n\nThis data shows changes in park visit frequency relative to pre-pandemic levels. For example, in the table above, we can see that total New York park visits were down 2 points on February 15th 2020 and up 13 points on February 16th 2020.\n\n\nCode\n# Step 3: Visualization for total NY park frequency\nny_summary = nyc_data %&gt;%\n  filter(county == \"Total\")\nny_summary$date = as.Date(ny_summary$date)\n\nggplot(ny_summary, aes(x = date, y = parks, fill = parks)) +\n    geom_bar(stat = \"identity\") +\n    theme_minimal() +\n    labs(title = \"NY State Park Frequency\", x = \"Date\", y = \"Indexed frequency levels compared to pre-pandemic\") +\n    theme(axis.text.x = element_text(angle = 45))\n\n\n\n\n\nSince the Mobility data is defined by counties and our NYC crimes data is defined by borough, we can filter for counties that encompass in the 5 NYC boroughs.\n\n\nCode\nselected_regions &lt;- nyc_data %&gt;%\n  filter(county %in% c(\"Bronx County\", \"Kings County\", \"Queens County\", \n                             \"New York County\", \"Richmond County\"))\n\n# Replace borough names\nselected_regions &lt;- selected_regions %&gt;%\n  mutate(county = case_when(\n    county == \"Bronx County\" ~ \"BRONX\",\n    county == \"Kings County\" ~ \"BROOKLYN\",\n    county == \"Queens County\" ~ \"QUEENS\",\n    county == \"New York County\" ~ \"MANHATTAN\",\n    county == \"Richmond County\" ~ \"STATEN ISLAND\",\n    TRUE ~ county\n  ))\n\n\nNext we test whether there are missing values in selected boroughs.\n\n\nCode\nna_count_parks_percent_change &lt;- sum(is.na(selected_regions$parks_percent_change_from_baseline))\n\nprint(na_count_parks_percent_change)\n\n\n[1] 0\n\n\nThe result shows that the dataset is complete without missing values. Then we can draw the summarized bar chart based on selected boroughs.\n\n\nCode\nlibrary(scales)\n\n\nWarning: package 'scales' was built under R version 4.1.2\n\n\nCode\nselected_regions$date = as.Date(selected_regions$date)\nggplot(selected_regions, aes(fill=county, y=parks, x=date)) + \n    geom_bar(position=\"stack\", stat=\"identity\") +\n    theme_minimal() +\n    labs(title = \"NYC Park Frequency\", x = \"Date\", y = \"Indexed frequency levels compared to pre-pandemic\") +\n    theme(axis.text.x = element_text(angle = 45)) +\n    scale_x_date(date_labels = \"%b-%d-%Y\")\n\n\nWarning: Removed 8 rows containing missing values (`position_stack()`).\n\n\n\n\n\nSince the data is tough to read in detail, we can summarize it by each month of data collected\n\n\nCode\nselected_regions$date = as.Date(selected_regions$date)\nmonthly_values = selected_regions %&gt;% \n    group_by(month = lubridate::floor_date(date, 'month'), county) %&gt;%\n    summarize(sum = sum(parks))\n\n\n`summarise()` has grouped output by 'month'. You can override using the\n`.groups` argument.\n\n\nCode\nggplot(monthly_values, aes(fill=county, y=sum, x=month)) + \n    geom_bar(position=\"stack\", stat=\"identity\") +\n    theme_minimal() +\n    labs(title = \"NYC Park Frequency by Month\", x = \"Date\", y = \"Indexed frequency levels compared to pre-pandemic\") +\n    theme(axis.text.x = element_text(angle = 45))\n\n\nWarning: Removed 2 rows containing missing values (`position_stack()`)."
  },
  {
    "objectID": "results.html#nyc-park-total-crimes-by-borough",
    "href": "results.html#nyc-park-total-crimes-by-borough",
    "title": "3  Results",
    "section": "3.1 NYC Park Total Crimes by Borough",
    "text": "3.1 NYC Park Total Crimes by Borough\nWe first get an idea of the total crime distribution in NYC boroughs.\n\n\nCode\nlibrary(readxl)\nlibrary(dplyr)\n\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\nCode\nlibrary(ggplot2)\nlibrary(tidyr)\n\n\nWarning: package 'tidyr' was built under R version 4.1.2\n\n\nCode\nlibrary(lubridate)\n\n\nWarning: package 'lubridate' was built under R version 4.1.2\n\n\n\nAttaching package: 'lubridate'\n\n\nThe following objects are masked from 'package:base':\n\n    date, intersect, setdiff, union\n\n\n\n\nCode\n# Initializes an empty data frame to store data for all quarters\nall_data &lt;- data.frame()\n\nfor (year in 2015:2023) {\n    for (quarter in 1:4) {\n        # Skip Q4 2023\n        if (year == 2023 && quarter == 4) {\n            next\n        }\n\n        file_path &lt;- sprintf(\"~/Desktop/crime_data/nyc-park-crime-stats-q%d-%d.xlsx\", quarter, year)\n\n        temp_data &lt;- read_excel(file_path, skip = 2)  \n\n        # Uniform column name\n        colnames(temp_data) &lt;- c(\"PARK\", \"BOROUGH\", \"SIZE_ACRES\", \"CATEGORY\", \"MURDER\", \"RAPE\", \"ROBBERY\", \"FELONY_ASSAULT\", \"BURGLARY\", \"GRAND_LARCENY\", \"GRAND_LARCENY_MV\", \"TOTAL\")\n\n        # Add a time period column\n        temp_data$Time_Period &lt;- sprintf(\"%d Q%d\", year, quarter)\n\n        # Merge into the master data framework\n        all_data &lt;- rbind(all_data, temp_data)\n        \n        all_data &lt;- all_data[all_data$BOROUGH != \"BOROUGH\", ]\n        \n        all_data &lt;- all_data[all_data$BOROUGH != \"BROOKLYN/QUEENS\", ]\n    }\n}\n\n\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\nNew names:\n• `` -&gt; `...2`\n• `` -&gt; `...3`\n• `` -&gt; `...4`\n• `` -&gt; `...5`\n• `` -&gt; `...6`\n• `` -&gt; `...7`\n• `` -&gt; `...8`\n• `` -&gt; `...9`\n• `` -&gt; `...10`\n• `` -&gt; `...11`\n• `` -&gt; `...12`\n\n\n\n\nCode\n# Calculate the total number of crimes for each quarter and borough\ncrime_stats &lt;- all_data %&gt;%\n  filter(!is.na(BOROUGH)) %&gt;%  # Exclude the rows where BOROUGH shows NA\n  group_by(Time_Period, BOROUGH) %&gt;%\n  summarize(Total_Crimes = sum(as.numeric(TOTAL), na.rm = TRUE))\n\n\n`summarise()` has grouped output by 'Time_Period'. You can override using the\n`.groups` argument.\n\n\n\n\nCode\ncustom_colors &lt;- c(\"orange\", \"skyblue\",\"pink\", \"#4DAF4A\", \"purple\")\n\n# draw time series plot\nggplot(crime_stats, aes(x = Time_Period, y = Total_Crimes, fill = BOROUGH)) +\n    geom_bar(stat=\"identity\", position = position_dodge()) +\n    theme_minimal() +\n    scale_fill_manual(values = custom_colors) +  \n    labs(title=\"NYC Park Crime Trends by Borough\", x=\"Time Period\", y=\"Total Crimes\") +\n    theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\nThis plot shows trends of total crimes by borough in different NYC boroughs. The crime data is from 2015 Spring to 2023 Autumn.\nGenerally, MANHATTAN and BROOKLYN have the most total crimes. This may result from their large populations and high densities of population. In contrast, STATEN ISLAND has the least total crimes for similar potential reasons. This may be also related to population characteristics of residence (income, races..).\nWe also notice that crimes happen more in Q3 (the third quarter) each year. There are increasing trends from 2015 to 2019 and plummets from 2020 to 2021. The cause may be the pandemic, when lockdown and disease happened more often."
  },
  {
    "objectID": "results.html#heatmap-of-total-crimes",
    "href": "results.html#heatmap-of-total-crimes",
    "title": "3  Results",
    "section": "3.2 Heatmap of Total Crimes",
    "text": "3.2 Heatmap of Total Crimes\nHeatmap based on quarters and boroughs shows directly the seasonal patterns and densities of crimes.\n\n\nCode\nggplot(crime_stats, aes(x = Time_Period, y = BOROUGH, fill = Total_Crimes)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"lightblue\", high = \"red\") +\n  theme_minimal() +\n  labs(title = \"NYC Park Crime Heatmap by Borough and Year\",\n       x = \"Year\",\n       y = \"Borough\",\n       fill = \"Total Crimes\") +\n  theme(axis.text.x = element_text(angle = 90))\n\n\n\n\n\nThere appears to be a recurring pattern within each year, suggesting a seasonal trend in crime numbers. For instance, the third quarters consistently show higher crime rates across multiple years. This may result from the weather and temperature. It seems crimes seldom take place in winter, but more in autumn.\nSome years stand out with overall higher crime rates across all boroughs, including 2017, 2018, 2019 and 2022. This could be indicative of broader societal factors affecting crime rates, such as economic downturns or changes in policing policy.\nThe intensity of colors varies across boroughs, indicating that some areas consistently experience higher crime rates than others. For example, MANHATTAN and BROOKLYN show more intense colors compared to STATEN ISLAND. Although STATEN ISLAND reports few crimes, we can still see light strips in the heatmap which indicate seasonal trends of crimes. This is hard to capture in the previous bar chart."
  },
  {
    "objectID": "results.html#trends-in-total-crimes",
    "href": "results.html#trends-in-total-crimes",
    "title": "3  Results",
    "section": "3.3 Trends in Total Crimes",
    "text": "3.3 Trends in Total Crimes\nTo see the trends more clearly for boroughs, we draw separate bar charts with LOESS smoothing lines to illustrate the trends.\n\n\nCode\n# Function: Converts a string in the format \"2019 Q1\" to a date\nconvert_to_date &lt;- function(time_period) {\n  parts &lt;- strsplit(time_period, \" \")[[1]]\n  year &lt;- parts[1]\n  quarter &lt;- substr(parts[2], 2, 2)\n\n  month &lt;- match(quarter, c(\"1\", \"2\", \"3\", \"4\")) * 3 - 2\n  as.Date(paste(year, sprintf(\"%02d\", month), \"01\", sep = \"-\"))\n}\n\ncrime_stats$Time_Period &lt;- sapply(crime_stats$Time_Period, convert_to_date)\n\n\n\n\nCode\n# Plot the time series for each borough and add a LOESS smoothing line\nboroughs &lt;- unique(crime_stats$BOROUGH)\n\nfor (borough in boroughs) {\n  borough_data &lt;- filter(crime_stats, BOROUGH == borough)\n  \n  p &lt;- ggplot(borough_data, aes(x = Time_Period, y = Total_Crimes)) +\n    geom_bar(stat = \"identity\", position = position_dodge(), aes(fill = BOROUGH)) +\n    geom_smooth(method = \"loess\", se = FALSE, linetype = 'solid', size = 1, color = \"black\") +\n    scale_fill_manual(values = custom_colors) +\n    theme_minimal() +\n    labs(title = paste(\"NYC Park Crime Trends in\", borough),\n         x = \"Time Period\",\n         y = \"Total Crimes\") +\n    theme(axis.text.x = element_text(angle = 90))\n  \n  print(p)\n}\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\nThe general trends for BROOKLYN, MANHATTAN, QUEENS and STATEN ISLAND are similar. They all show an increasing trend from 2015 to 2019, and then crime numbers dropped during the pandemic. In the end, crime data again increase, with a tendency to surpass the previous crime records. However, it’s different for BRONX. The crimes start decreasing before the pandemic, and then decline gradually and slowly. This trend in BRONX is clear in this plot, but not apparent in the previous section."
  },
  {
    "objectID": "results.html#nyc-park-crime-by-crime-categories",
    "href": "results.html#nyc-park-crime-by-crime-categories",
    "title": "3  Results",
    "section": "3.4 NYC Park Crime by Crime Categories",
    "text": "3.4 NYC Park Crime by Crime Categories\nHere we look into crime details for different boroughs. We focus on the crime categories.\n\n\nCode\nlong_data &lt;- all_data %&gt;%\n  pivot_longer(\n    cols = c(\"MURDER\", \"RAPE\", \"ROBBERY\", \"FELONY_ASSAULT\", \"BURGLARY\", \"GRAND_LARCENY\", \"GRAND_LARCENY_MV\"),\n    names_to = \"CRIME_TYPE\",\n    values_to = \"CRIME_COUNT\"\n  )\n\ncrime_type_stats &lt;- long_data %&gt;%\n  filter(!is.na(BOROUGH)) %&gt;%\n  group_by(Time_Period, BOROUGH, CRIME_TYPE) %&gt;%\n  summarize(Total_Crimes = sum(as.numeric(CRIME_COUNT), na.rm = TRUE))\n\n\n`summarise()` has grouped output by 'Time_Period', 'BOROUGH'. You can override\nusing the `.groups` argument.\n\n\nCode\n# Generate a line chart for each borough\nboroughs &lt;- unique(crime_type_stats$BOROUGH)\n\nfor (borough in boroughs) {\n  borough_data &lt;- filter(crime_type_stats, BOROUGH == borough)\n  \n  p &lt;- ggplot(borough_data, aes(x = Time_Period, y = Total_Crimes, color = CRIME_TYPE, group = CRIME_TYPE)) +\n    geom_line() +\n    theme_minimal() +\n    labs(title = paste(\"NYC Park Crime Trends in\", borough), x = \"Time Period\", y = \"Number of Crimes\") +\n    theme(axis.text.x = element_text(angle = 90), legend.position = \"bottom\")\n  \n  print(p)\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGenerally, robbery, felony assault and grand larceny are three common crime categories in all boroughs. Crime numbers of these three types are much higher than other crime types. Other crimes like rape rarely happen, less than 5 per quarter.\nWe notice there are obvious differences in boroughs. In BRONX, robbery is always the most common crime except the year 2020. However, grand larceny is the most common crime in BROOKLYN, MANHATTAN and QUEENS. This may be related to population density, tourist activity and commercial activity in these areas. STATEN ISLAND does not show any trend or dominant crime types, different from other boroughs. This aligns with the small crime numbers in STATE ISLAND. It seems that STATEN ISLAND is relatively safer than other boroughs.\nThese observed crime patterns may be influenced by different socio-economic conditions across regions, such as poverty levels, unemployment rates, education levels, and community resources."
  },
  {
    "objectID": "results.html#relationships-between-park-sizes-and-crimes",
    "href": "results.html#relationships-between-park-sizes-and-crimes",
    "title": "3  Results",
    "section": "3.5 Relationships between Park Sizes and Crimes",
    "text": "3.5 Relationships between Park Sizes and Crimes\n\n\nCode\nall_data$TOTAL &lt;- as.numeric(all_data$TOTAL)\n\n# Create a summary data frame\npark_crime_stats &lt;- all_data %&gt;%\n  filter(!is.na(BOROUGH)) %&gt;%\n  group_by(PARK, BOROUGH) %&gt;%\n  summarize(\n    Total_Crimes = sum(TOTAL, na.rm = TRUE),\n    Park_Size = mean(as.numeric(SIZE_ACRES), na.rm = TRUE) \n  ) %&gt;%\n  ungroup() \n\n\n`summarise()` has grouped output by 'PARK'. You can override using the\n`.groups` argument.\n\n\n\n\nCode\n# Create the scatterplot\nggplot(park_crime_stats, aes(x = Park_Size, y = Total_Crimes, color = BOROUGH)) +\n  geom_point() +\n  #scale_x_log10() +  # Logarithmic scale for park size\n  theme_minimal() +\n  labs(\n    title = \"Relationship between Park Size, Crime, and Borough\",\n    x = \"Park Size (Acres, log scale)\",\n    y = \"Total Crimes\",\n    color = \"Borough\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nOutliers make this plot unclear. The majority of data points stack together. We will remove the outliers.\n\n\nCode\n# Coomputer IQR\niqr_stats &lt;- park_crime_stats %&gt;%\n  summarize(\n    Q1 = quantile(Total_Crimes, 0.25, na.rm = TRUE),\n    Q3 = quantile(Total_Crimes, 0.75, na.rm = TRUE)\n  ) %&gt;%\n  mutate(IQR = Q3 - Q1)\n\n# Define ranges for outliers\nlower_bound &lt;- iqr_stats$Q1 - 1.5 * iqr_stats$IQR\nupper_bound &lt;- iqr_stats$Q3 + 1.5 * iqr_stats$IQR\n\n# Filter out outliers\npark_crime_stats_filtered &lt;- park_crime_stats %&gt;%\n  filter(Total_Crimes &gt;= lower_bound & Total_Crimes &lt;= upper_bound)\n\n# Create the scatterplot again\nggplot(park_crime_stats_filtered, aes(x = Park_Size, y = Total_Crimes, color = BOROUGH)) +\n  geom_point() +\n  theme_minimal() +\n  labs(\n    title = \"Relationship between Park Size, Crime, and Borough (Outliers Removed)\",\n    x = \"Park Size (Acres)\",\n    y = \"Total Crimes\",\n    color = \"Borough\"\n  ) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\nThere’s a dense cluster of points near the origin, indicating that smaller parks tend to have lower counts of total crimes. This could suggest that park size is a factor in crime occurrence, with smaller parks offering fewer opportunities for crime. However, There is no distinct upward trend line that would indicate a clear positive correlation between park size and crime rates.\nCrime data have different distributions based on boroughs. It’s noticeable that certain boroughs like MANHATTAN and BROOKLYN have points that lie closly on the y-axis (total crimes), indicating these boroughs have higher crime rates. STATEN ISLAND tends to have much lower crime rates no matter what the park size is. This also verifies STATEN ISLAND is safter than other boroughs."
  }
]