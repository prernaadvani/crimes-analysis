# Data

## Description

As we are studying crimes at NYC parks and potential reasons, we collected three datasets: crimes, unemployment, and mobility data.

First, we collected crime data in NYC from NYPD official websites focused on crime statistics. The link for the data is [NYPD Crime Statistics](https://www.nyc.gov/site/nypd/stats/crime-statistics/park-crime-stats.page). The data covers quarters from 2014 to 2023. The data for each quarter shows features like numbers of crimes, park sizes, and boroughs. The data format is an excel file for each quarter that we plan to download onto our local drives and import into R. We will then clean and merge data for all quarters. For our study, we first focused on three factors: total number of different types of crimes, park size categories, and boroughs. Further, we investigated the influence of specific types of crimes.

Second, we collected unemployment data from U.S. Bureau of Labor Statistics official website focused on NYC area. The link of data is [NYC Unemployment Statistics](https://www.bls.gov/regions/northeast/data/xg-tables/ro2xglausnyc.htm). Additionally, [BLS Data Finder](https://beta.bls.gov/dataQuery/search) offered on this website is able to search unemployment data for NYC. We are downloading an excel file with all of the data from 2013-2023 onto our local drive and importing it into R. Monthly unemployment data is available from 2013 to 2023. Columns include the year, month, and annual average unemployment in wide format.

Last, we looked at high level mobility data from Google Community Mobility Reports. The link of data is [Mobility Data](https://www.google.com/covid19/mobility/). Daily data of movement trend in places such as parks is available in the Covid-19 period. A few restrictions on this data include: it is only available from February 2020 to October 2022, and the data must be scraped from the published reports. If we want to use the data, we will have to use a third party source that has scraped data into a csv file. The link for a potential scrape is from [this GitHub Repo](https://github.com/ActiveConclusion/COVID19_mobility/blob/master/google_reports/mobility_report_US.csv). Though the dataset includes other locations (such as grocery stores), and other regions (different states in the US), we will only be focusing on parks and NYC, if permitted to use this dataset.

## Research Plan

We plan to use NYC crimes data to track how the frequency of different types of crimes has changed across time and different boroughs. We will then use unemployment data to glean and additional insights on correlations that may exist. Lastly, if permitted, we can derive any impacts of park visit frequency from February 2020-October 2022. A few different ideas for analysis are included below:

1. Time series analysis for crimes data. We will conduct time series analysis to look into components including long term trends, seasonality (systematic, calendar related movements), and irregularity (unsystematic, short term fluctuations). In addition to overall crime trends, we will further analyze how specific types of crimes (murder, rape, etc.) vary over time.

2. Heatmaps and bar charts for crimes data. We will illustrate crimes data in heatmaps based on boroughs and periods to find time and regional differences. We will use bar charts to show the total number of crimes in each borough, allowing for easy comparison across regions. We will also include bar charts that compare the annual crimes in each borough across different years.

3. Relationship between crimes and employment rate. We will look into trends for total number of crimes and unemployment rates both annually and quarterly. We will first demonstrate these two variables in scatterplots. In detail, we will add trend lines and calculate correlation coefficients for these scatterplots to quantify the strength of the relationship.

4. Relationship between crimes and mobility data. For February 2020 to October 2022, we may look into the number of crimes and park attendance levels, investigating whether visitor flow affects crimes.

## Missing value analysis

### Crimes Data

First, we examine the crimes datasets. We will begin by first pulling data for 3Q23 for a high level overview. After determining data cleans, we will merge data for multiple quarters. We can see that there are few missing values in our data. We can just delete the records with missing values.

```{r}
library(readxl)
nyc_park_crime_stats_q3_2023 <- read_excel("~/Desktop/nyc-park-crime-stats-q3-2023.xlsx") #read data

# show part of data
head(nyc_park_crime_stats_q3_2023)
```
We can see that there are a few extra rows of data at the top and row 3 needs to be the header. 

```{r}
colnames(nyc_park_crime_stats_q3_2023) = nyc_park_crime_stats_q3_2023[3,] #set row 3 as header
nyc_park_crime_stats_q3_2023 = nyc_park_crime_stats_q3_2023[-c(1,2,3), ] #remove first 3 rows of data
head(nyc_park_crime_stats_q3_2023) #new data column names
```


Here, we show the features of crimes data: park, borough, park size, number of crimes by type of crime.

```{r}
# examine whether thre are missing values
colSums(is.na(nyc_park_crime_stats_q3_2023))
```
Here, we can see there are only some missing values in each column, which are negligible. Therefore we just delete the records with missing values.

```{r}
nyc_park_crime_stats_q3_2023_clean <- na.omit(nyc_park_crime_stats_q3_2023)
head(nyc_park_crime_stats_q3_2023_clean)
```
To visualize the crimes by borough, we first compute the total crimes.

```{r}
library(dplyr)
nyc_park_crime_stats_q3_2023_clean <- nyc_park_crime_stats_q3_2023_clean %>%
  mutate_at(vars(TOTAL), as.numeric)

# compute total crimes for boroughs
borough_crime_totals <- nyc_park_crime_stats_q3_2023_clean %>%
  group_by(BOROUGH) %>%
  summarize(Total_Crimes = sum(TOTAL, na.rm = TRUE))

print(borough_crime_totals)
```
Then we use bar chart to show the results.

```{r}
library(ggplot2)
borough_data = as.data.frame(borough_crime_totals)

ggplot(borough_data, aes(x = BOROUGH, y = Total_Crimes, fill = BOROUGH)) +
    geom_bar(stat="identity") +
    theme_minimal() +
    labs(title="NYC Park Crime Distribution by Borough", x="Borough", y="Total Crimes") +
    theme(axis.text.x = element_text(angle = 90))
```

### Unemployment Rate Data

Then, we examine the dataset for unemployment rates.

```{r}
unemployment_rate <- read_excel("~/Desktop/unemployment_rate.xlsx") #read data
print(unemployment_rate)
```

It's obvious that the missing values are average unemployment rates for each year and the last two months in 2023. For the average rates, we can directly compute the average rates based on monthly rates.

```{r}
unemployment_rate$Avg <- rowMeans(unemployment_rate[, 2:13], na.rm = TRUE)
```

As for missing values for the last two months in 2023, it's reasonable because there is no data available yet for months in the future. We can just ignore the missing values here.


```{r}
print(unemployment_rate)
```
The following line graph is a time series visualization showing the variation in unemployment rates for each month across different years. There are no gaps in this plot, verifying no missing values in the dataset.

```{r}
library(ggplot2)
library(tidyr)
library(dplyr)

unemployment_long <- unemployment_rate %>%
  pivot_longer(cols = Jan:Dec, names_to = "Month", values_to = "UnemploymentRate") %>%
  mutate(Month = match(Month, month.abb))

ggplot(unemployment_long, aes(x = Year + (Month-1)/12, y = UnemploymentRate)) +
  geom_line() +
  scale_x_continuous(breaks = unique(unemployment_long$Year)) +
  labs(title = "Monthly Unemployment Rate Over Years",
       x = "Year",
       y = "Unemployment Rate (%)") +
  theme_minimal()
```
### Mobility Data

We examine the mobility dataset. We only focus on the feature: parks_percent_change_from_baseline.

```{r}
library(readr)
library(dplyr)
library(ggplot2)

# Step 1: Read the CSV file
file_path <- "~/Desktop/2022_US_Region_Mobility_Report.csv"  # read data
data <- read_csv(file_path)

# Step 2: Filter for New York Data
nyc_data <- filter(data, sub_region_1 == "New York") # Replace 'region' with the correct column name

# Step 3: Summarizing parks_percent_change_from_baseline by borough
borough_summary <- nyc_data %>%
    group_by(sub_region_2) %>%
    summarize(Average_Metric = mean(parks_percent_change_from_baseline, na.rm = TRUE))

# Step 4: Visualization
ggplot(borough_summary, aes(x = sub_region_2, y = Average_Metric, fill = sub_region_2)) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    labs(title = "Title", x = "Borough", y = "Metric") +
    theme(axis.text.x = element_text(angle = 90))
```
Noticing there are more boroughs than our target boroughs. We will filter the boroughs and replace the borough names to make it compatible with the crime dataset.

```{r}
# List unique values in the sub_region_2 column
unique_values <- unique(nyc_data$sub_region_2)

# Print the unique values
print(unique_values)
```

```{r}
selected_regions <- nyc_data %>%
  filter(sub_region_2 %in% c("Bronx County", "Kings County", "Queens County", 
                             "New York County", "Richmond County"))

# Replace borough names
selected_regions <- selected_regions %>%
  mutate(sub_region_2 = case_when(
    sub_region_2 == "Bronx County" ~ "BRONX",
    sub_region_2 == "Kings County" ~ "BROOKLYN",
    sub_region_2 == "Queens County" ~ "QUEENS",
    sub_region_2 == "New York County" ~ "MANHATTAN",
    sub_region_2 == "Richmond County" ~ "STATEN ISLAND",
    TRUE ~ sub_region_2
  ))

head(selected_regions)
```
Next we test whether there are missing values in selected boroughs.

```{r}
na_count_parks_percent_change <- sum(is.na(selected_regions$parks_percent_change_from_baseline))

print(na_count_parks_percent_change)
```

The result shows that the dataset is complete without missing values. Then we can draw the summarized bar chart based on selected boroughs.

```{r}
borough_summary <- selected_regions %>%
    group_by(sub_region_2) %>%
    summarize(Average_Metric = mean(parks_percent_change_from_baseline, na.rm = TRUE))

# Visualization
ggplot(borough_summary, aes(x = sub_region_2, y = Average_Metric, fill = sub_region_2)) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    labs(title = "Average Parks Percent Change from Baseline by Borough", 
         x = "Borough", 
         y = "Average Percent Change") +
    theme(axis.text.x = element_text(angle = 90))
```
